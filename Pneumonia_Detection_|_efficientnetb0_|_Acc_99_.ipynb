{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Pneumonia Detection | efficientnetb0 | Acc: 99%",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thesis-AfaanOromooChatGPT2025/MedPromptX/blob/main/Pneumonia_Detection_%7C_efficientnetb0_%7C_Acc_99_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "paultimothymooney_chest_xray_pneumonia_path = kagglehub.dataset_download('paultimothymooney/chest-xray-pneumonia')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "hLY5-HKnwE8g"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import needed modules"
      ],
      "metadata": {
        "id": "CKeVGxZ5GG6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.9.1"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-04-13T19:34:56.85114Z",
          "iopub.execute_input": "2023-04-13T19:34:56.851411Z",
          "iopub.status.idle": "2023-04-13T19:36:11.228337Z",
          "shell.execute_reply.started": "2023-04-13T19:34:56.851384Z",
          "shell.execute_reply": "2023-04-13T19:36:11.227157Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "7uS1AKJBwE8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import system libs\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import pathlib\n",
        "import itertools\n",
        "\n",
        "# import data handling tools\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# import Deep learning Libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Ignore Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print ('modules loaded')"
      ],
      "metadata": {
        "id": "CeMcAy_5GG6s",
        "execution": {
          "iopub.status.busy": "2023-04-13T19:36:11.231237Z",
          "iopub.execute_input": "2023-04-13T19:36:11.231993Z",
          "iopub.status.idle": "2023-04-13T19:36:15.833343Z",
          "shell.execute_reply.started": "2023-04-13T19:36:11.231948Z",
          "shell.execute_reply": "2023-04-13T19:36:15.832152Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "SA_gwvwnGG6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Read data and store it in dataframe**"
      ],
      "metadata": {
        "id": "e4reLHLHabWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data paths with labels\n",
        "data_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/train'\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "folds = os.listdir(data_dir)\n",
        "for fold in folds:\n",
        "    foldpath = os.path.join(data_dir, fold)\n",
        "    filelist = os.listdir(foldpath)\n",
        "    for file in filelist:\n",
        "        fpath = os.path.join(foldpath, file)\n",
        "        filepaths.append(fpath)\n",
        "        labels.append(fold)\n",
        "\n",
        "# Concatenate data paths with labels into one dataframe\n",
        "Fseries = pd.Series(filepaths, name= 'filepaths')\n",
        "Lseries = pd.Series(labels, name='labels')\n",
        "df = pd.concat([Fseries, Lseries], axis= 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T19:36:15.834815Z",
          "iopub.execute_input": "2023-04-13T19:36:15.836059Z",
          "iopub.status.idle": "2023-04-13T19:36:16.318671Z",
          "shell.execute_reply.started": "2023-04-13T19:36:15.836018Z",
          "shell.execute_reply": "2023-04-13T19:36:16.317683Z"
        },
        "trusted": true,
        "id": "PfQyp2wWwE8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T19:36:16.321444Z",
          "iopub.execute_input": "2023-04-13T19:36:16.322179Z",
          "iopub.status.idle": "2023-04-13T19:36:16.342964Z",
          "shell.execute_reply.started": "2023-04-13T19:36:16.322139Z",
          "shell.execute_reply": "2023-04-13T19:36:16.341828Z"
        },
        "trusted": true,
        "id": "mI0aXlLjwE8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Split dataframe into train, valid, and test**"
      ],
      "metadata": {
        "id": "SHAFGSFBwE8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataframe\n",
        "train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 123)\n",
        "\n",
        "# valid and test dataframe\n",
        "valid_df, test_df = train_test_split(dummy_df,  train_size= 0.6, shuffle= True, random_state= 123)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T19:36:16.344675Z",
          "iopub.execute_input": "2023-04-13T19:36:16.345034Z",
          "iopub.status.idle": "2023-04-13T19:36:16.360588Z",
          "shell.execute_reply.started": "2023-04-13T19:36:16.344998Z",
          "shell.execute_reply": "2023-04-13T19:36:16.359501Z"
        },
        "trusted": true,
        "id": "XR4-3HC-wE8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create image data generator**"
      ],
      "metadata": {
        "id": "arw_MtyywE8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# crobed image size\n",
        "batch_size = 16\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "# Recommended : use custom function for test data batch size, else we can use normal batch size.\n",
        "ts_length = len(test_df)\n",
        "test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size\n",
        "\n",
        "# This function which will be used in image data generator for data augmentation, it just take the image and return it again.\n",
        "def scalar(img):\n",
        "    return img\n",
        "\n",
        "tr_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
        "ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
        "\n",
        "train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "\n",
        "valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
        "\n",
        "# Note: we will use custom test_batch_size, and make shuffle= false\n",
        "test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
        "                                    color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T19:36:16.36182Z",
          "iopub.execute_input": "2023-04-13T19:36:16.362232Z",
          "iopub.status.idle": "2023-04-13T19:36:24.226822Z",
          "shell.execute_reply.started": "2023-04-13T19:36:16.362197Z",
          "shell.execute_reply": "2023-04-13T19:36:24.225635Z"
        },
        "trusted": true,
        "id": "k5uRrNW7wE8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Show sample from train data**"
      ],
      "metadata": {
        "id": "jWsA8ZAKwE8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_dict = train_gen.class_indices      # defines dictionary {'class': index}\n",
        "classes = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\n",
        "images, labels = next(train_gen)      # get a batch size samples from the generator\n",
        "\n",
        "plt.figure(figsize= (20, 20))\n",
        "\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    image = images[i] / 255       # scales data to range (0 - 255)\n",
        "    plt.imshow(image)\n",
        "    index = np.argmax(labels[i])  # get image index\n",
        "    class_name = classes[index]   # get class of image\n",
        "    plt.title(class_name, color= 'blue', fontsize= 12)\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T19:51:03.759283Z",
          "iopub.execute_input": "2023-04-13T19:51:03.759661Z",
          "iopub.status.idle": "2023-04-13T19:51:05.985447Z",
          "shell.execute_reply.started": "2023-04-13T19:51:03.759626Z",
          "shell.execute_reply": "2023-04-13T19:51:05.984036Z"
        },
        "trusted": true,
        "id": "41W7MYdRwE8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Structure**"
      ],
      "metadata": {
        "id": "57eDFl3oGG65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Generic Model Creation**"
      ],
      "metadata": {
        "id": "3wvOKjeRGG65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Model Structure\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "class_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n",
        "\n",
        "# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n",
        "# we will use efficientnetb3 from EfficientNet family.\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n",
        "# base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
        "    Dense(256, kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n",
        "                bias_regularizer= regularizers.l1(0.006), activation= 'relu'),\n",
        "    Dropout(rate= 0.45, seed= 123),\n",
        "    Dense(class_count, activation= 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "kDT4CV15abWT",
        "execution": {
          "iopub.status.busy": "2023-04-13T19:36:26.249136Z",
          "iopub.execute_input": "2023-04-13T19:36:26.249445Z",
          "iopub.status.idle": "2023-04-13T19:36:30.207227Z",
          "shell.execute_reply.started": "2023-04-13T19:36:26.249414Z",
          "shell.execute_reply": "2023-04-13T19:36:30.206003Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Train model**"
      ],
      "metadata": {
        "id": "ap89fjdxGG67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16   # set batch size for training\n",
        "epochs = 10   # number of all epochs in training\n",
        "\n",
        "history = model.fit(x= train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen,\n",
        "                    validation_steps= None, shuffle= False)"
      ],
      "metadata": {
        "id": "0Uk3BTERGG67",
        "execution": {
          "iopub.status.busy": "2023-04-13T19:36:30.208937Z",
          "iopub.execute_input": "2023-04-13T19:36:30.209912Z",
          "iopub.status.idle": "2023-04-13T19:49:21.121982Z",
          "shell.execute_reply.started": "2023-04-13T19:36:30.209857Z",
          "shell.execute_reply": "2023-04-13T19:49:21.120905Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Display model performance**"
      ],
      "metadata": {
        "id": "dNKq6ebOGG67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define needed variables\n",
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L0Bj0Sp_GG68",
        "execution": {
          "iopub.status.busy": "2023-04-13T19:49:21.126137Z",
          "iopub.execute_input": "2023-04-13T19:49:21.126441Z",
          "iopub.status.idle": "2023-04-13T19:49:21.638483Z",
          "shell.execute_reply.started": "2023-04-13T19:49:21.126412Z",
          "shell.execute_reply": "2023-04-13T19:49:21.637514Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate model**"
      ],
      "metadata": {
        "id": "MySXhfAJGG68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ts_length = len(test_df)\n",
        "test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size\n",
        "\n",
        "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
        "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
        "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
        "\n",
        "print(\"Train Loss: \", train_score[0])\n",
        "print(\"Train Accuracy: \", train_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Validation Loss: \", valid_score[0])\n",
        "print(\"Validation Accuracy: \", valid_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Test Loss: \", test_score[0])\n",
        "print(\"Test Accuracy: \", test_score[1])"
      ],
      "metadata": {
        "id": "wSKDkyXXGG68",
        "execution": {
          "iopub.status.busy": "2023-04-13T19:49:21.640014Z",
          "iopub.execute_input": "2023-04-13T19:49:21.64063Z",
          "iopub.status.idle": "2023-04-13T19:49:38.332632Z",
          "shell.execute_reply.started": "2023-04-13T19:49:21.640593Z",
          "shell.execute_reply": "2023-04-13T19:49:38.331339Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Get Predictions**"
      ],
      "metadata": {
        "id": "4l-DABtFGG68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict_generator(test_gen)\n",
        "y_pred = np.argmax(preds, axis=1)"
      ],
      "metadata": {
        "id": "GDFj7MZdGG69",
        "execution": {
          "iopub.status.busy": "2023-04-13T19:49:38.334186Z",
          "iopub.execute_input": "2023-04-13T19:49:38.334973Z",
          "iopub.status.idle": "2023-04-13T19:49:45.36814Z",
          "shell.execute_reply.started": "2023-04-13T19:49:38.334929Z",
          "shell.execute_reply": "2023-04-13T19:49:45.367099Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Confusion Matrics and Classification Report**"
      ],
      "metadata": {
        "id": "aJscUTF6GG69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g_dict = test_gen.class_indices\n",
        "classes = list(g_dict.keys())\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(test_gen.classes, y_pred)\n",
        "\n",
        "plt.figure(figsize= (10, 10))\n",
        "plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation= 45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-13T19:49:45.369422Z",
          "iopub.execute_input": "2023-04-13T19:49:45.36979Z",
          "iopub.status.idle": "2023-04-13T19:49:45.708227Z",
          "shell.execute_reply.started": "2023-04-13T19:49:45.369752Z",
          "shell.execute_reply": "2023-04-13T19:49:45.707278Z"
        },
        "trusted": true,
        "id": "Oe6ptkIpwE8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
      ],
      "metadata": {
        "id": "tQR-UlD6GG69",
        "execution": {
          "iopub.status.busy": "2023-04-13T19:49:45.709806Z",
          "iopub.execute_input": "2023-04-13T19:49:45.710158Z",
          "iopub.status.idle": "2023-04-13T19:49:45.72316Z",
          "shell.execute_reply.started": "2023-04-13T19:49:45.710121Z",
          "shell.execute_reply": "2023-04-13T19:49:45.721969Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Save model**"
      ],
      "metadata": {
        "id": "SsIK5v0lGG69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = model.input_names[0][:-6]\n",
        "subject = 'Indian Rock Python'\n",
        "acc = test_score[1] * 100\n",
        "save_path = ''\n",
        "\n",
        "# Save model\n",
        "save_id = str(f'{model_name}-{subject}-{\"%.2f\" %round(acc, 2)}.h5')\n",
        "model_save_loc = os.path.join(save_path, save_id)\n",
        "model.save(model_save_loc)\n",
        "print(f'model was saved as {model_save_loc}')\n",
        "\n",
        "# Save weights\n",
        "weight_save_id = str(f'{model_name}-{subject}-weights.h5')\n",
        "weights_save_loc = os.path.join(save_path, weight_save_id)\n",
        "model.save_weights(weights_save_loc)\n",
        "print(f'weights were saved as {weights_save_loc}')"
      ],
      "metadata": {
        "id": "oy5ShUciGG6-",
        "execution": {
          "iopub.status.busy": "2023-04-13T19:49:45.724717Z",
          "iopub.execute_input": "2023-04-13T19:49:45.725073Z",
          "iopub.status.idle": "2023-04-13T19:49:46.789896Z",
          "shell.execute_reply.started": "2023-04-13T19:49:45.725037Z",
          "shell.execute_reply": "2023-04-13T19:49:46.788881Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Generate CSV files containing classes indicies & image size**"
      ],
      "metadata": {
        "id": "q2fsiEtEGG6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict = train_gen.class_indices\n",
        "img_size = train_gen.image_shape\n",
        "height = []\n",
        "width = []\n",
        "for _ in range(len(class_dict)):\n",
        "    height.append(img_size[0])\n",
        "    width.append(img_size[1])\n",
        "\n",
        "Index_series = pd.Series(list(class_dict.values()), name= 'class_index')\n",
        "Class_series = pd.Series(list(class_dict.keys()), name= 'class')\n",
        "Height_series = pd.Series(height, name= 'height')\n",
        "Width_series = pd.Series(width, name= 'width')\n",
        "class_df = pd.concat([Index_series, Class_series, Height_series, Width_series], axis= 1)\n",
        "csv_name = f'{subject}-class_dict.csv'\n",
        "csv_save_loc = os.path.join(save_path, csv_name)\n",
        "class_df.to_csv(csv_save_loc, index= False)\n",
        "print(f'class csv file was saved as {csv_save_loc}')"
      ],
      "metadata": {
        "id": "UiHQzq8XGG6-",
        "execution": {
          "iopub.status.busy": "2023-04-13T19:49:46.791495Z",
          "iopub.execute_input": "2023-04-13T19:49:46.79187Z",
          "iopub.status.idle": "2023-04-13T19:49:46.806183Z",
          "shell.execute_reply.started": "2023-04-13T19:49:46.791832Z",
          "shell.execute_reply": "2023-04-13T19:49:46.805115Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}