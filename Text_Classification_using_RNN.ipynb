{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 4033428,
          "sourceType": "datasetVersion",
          "datasetId": 2389764
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Text Classification using RNN",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thesis-AfaanOromooChatGPT2025/MedPromptX/blob/main/Text_Classification_using_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "falgunipatel19_biomedical_text_publication_classification_path = kagglehub.dataset_download('falgunipatel19/biomedical-text-publication-classification')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "arrfZdz9kpXP"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h3 style=\"text-align: center;\">Hello! Welcome to my notebook❤️\n"
      ],
      "metadata": {
        "id": "z09aqAQ0kpXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#read the data\n",
        "import pandas as pd\n",
        "df=pd.read_csv(\"/kaggle/input/biomedical-text-publication-classification/alldata_1_for_kaggle.csv\",encoding='latin1')\n",
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "WrxUPfnckpXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📎Initial Data Exploration and Cleaning"
      ],
      "metadata": {
        "id": "XT6EfywGkpXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "trusted": true,
        "id": "dDi1LZUTkpXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* data has no Null Values\n",
        "* its shape is(7570,3)"
      ],
      "metadata": {
        "id": "4iV5Z_H7kpXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check Duplicated vals\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "trusted": true,
        "id": "WtybegU9kpXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rename cols\n",
        "df = df.rename(columns={'0': 'labels', 'a': 'text'})"
      ],
      "metadata": {
        "trusted": true,
        "id": "ijnetpdekpXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df['labels'].unique()\n",
        "df['labels'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "id": "gpwMFTDekpXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The classification problem involves three distinct classes:\n",
        "> 1. **Thyroid Cancer**\n",
        "> 2. **Colon Cancer**\n",
        "> 3. **Lung Cancer**"
      ],
      "metadata": {
        "id": "vEQwVnFEkpXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['text'].values\n",
        "labels = df['labels'].values"
      ],
      "metadata": {
        "trusted": true,
        "id": "zaH9gmPpkpXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📎Spliting the data"
      ],
      "metadata": {
        "id": "gny6vLZ9kpXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42,shuffle=True,stratify=labels)\n",
        "\n",
        "print(\"Dimensions of X_train :\", X_train.shape)\n",
        "print(\"Dimensions of X_test  :\", X_test.shape)\n",
        "print(\"Dimensions of y_train :\", y_train.shape)\n",
        "print(\"Dimensions of y_test  :\", y_test.shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "JWlFJUb9kpXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **shuffle**:shuffle the data before splitting\n",
        "> * **stratify**: ensures that the class distribution in the training and testing sets is proportional to the class distribution in the original dataset."
      ],
      "metadata": {
        "id": "7UmXQzUVkpXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📎Text Tokenization and Sequence Conversion\n"
      ],
      "metadata": {
        "id": "iKe7wYhqkpXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "X_train_seq[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "_O9vanVNkpXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **Tokenizer**: Converts text into sequences of integers, with each integer representing a unique word.\n",
        "> * **fit_on_texts**: Updates the tokenizer’s vocabulary with words from the provided texts, building the word-to-integer mapping.\n",
        "> * **texts_to_sequences**: Transforms each text into a sequence of integers based on the word index created by fit_on_texts."
      ],
      "metadata": {
        "id": "eoCIBOzpkpXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📎Sequence Padding and Length Adjustment"
      ],
      "metadata": {
        "id": "G6emklZPkpXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_len = max([len(seq) for seq in X_train_seq])  # Maximum length of sequences\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
        "\n",
        "X_train_pad[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "8gzF2KJ8kpXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **pad_sequences**:Pads sequences to ensure that they all have the same length\n",
        "> * **maxlen**:  the maximum length of the sequences. Sequences longer than this length will be truncated, and shorter sequences will be padded.\n",
        "> * **padding**: 'pre' or 'post'. Whether to pad sequences at the beginning or the end (default is 'pre').\n",
        "> * **truncating**: 'pre' or 'post'. Whether to truncate sequences at the beginning or the end (default is 'pre')."
      ],
      "metadata": {
        "id": "iBggPJtlkpXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **difference between Padding and Truncating**\n",
        "> * **Padding**:To ensure all sequences in the dataset have the same length by adding extra values (usually zeros) to sequences that are shorter than the desired length.\n",
        "> * **Truncating**:To shorten sequences that exceed the maximum length by removing values from either the start or end of the sequence."
      ],
      "metadata": {
        "id": "CKYBcHlNkpXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  **max([len(seq) for seq in X_train_seq])**\n",
        "> *  it makes length equals to max length of sequence\n",
        "> * so you do not need to do any Truncating"
      ],
      "metadata": {
        "id": "EpmLtvpUkpXT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📎One-Hot Encoding"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-08T13:32:07.710553Z",
          "iopub.execute_input": "2024-08-08T13:32:07.711479Z",
          "iopub.status.idle": "2024-08-08T13:32:07.717413Z",
          "shell.execute_reply.started": "2024-08-08T13:32:07.711437Z",
          "shell.execute_reply": "2024-08-08T13:32:07.716327Z"
        },
        "id": "UyWtrbj-kpXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_ = label_encoder.fit_transform(y_train)\n",
        "y_test_ = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "\n",
        "y_train_cat = to_categorical(y_train_, num_classes=3)\n",
        "y_test_cat = to_categorical(y_test_, num_classes=3)\n",
        "\n",
        "y_train_cat\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "ODlGQBY1kpXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **LabelEncoder**: Converts categorical labels (strings) into integer labels\n",
        "> * **to_categorical**: Converts a class vector (integers) to binary class matrix (one-hot encoding), which is useful for categorical classification problems."
      ],
      "metadata": {
        "id": "TbjK048vkpXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📎RNN Architecture"
      ],
      "metadata": {
        "id": "RU-Y6kgHkpXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_len))\n",
        "model.add(SimpleRNN(128, return_sequences=False))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "trusted": true,
        "id": "75ATjHdfkpXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **Sequential**: A linear stack of layers. You can add layers to the model in a sequential manner.\n",
        "> * **Embedding**: Turns positive integers (indexes) into dense vectors of fixed size, often used as the first layer in text-based neural networks to convert words into vectors.\n",
        "> * **SimpleRNN**: A basic RNN layer that processes input sequences and has an internal state that captures temporal dependencies.\n",
        "> * **Dense**: A fully connected layer where each neuron is connected to every neuron in the previous layer."
      ],
      "metadata": {
        "id": "nNEpoWNNkpXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Sequential**:\n",
        "> * Initializes a new, empty model. Layers will be added sequentially."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-08T14:14:00.457993Z",
          "iopub.execute_input": "2024-08-08T14:14:00.458718Z",
          "iopub.status.idle": "2024-08-08T14:14:00.464639Z",
          "shell.execute_reply.started": "2024-08-08T14:14:00.458684Z",
          "shell.execute_reply": "2024-08-08T14:14:00.463494Z"
        },
        "id": "eM_i42PIkpXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Embedding Layer**:This layer converts the integer sequences of words (generated by Tokenizer) into dense vectors of fixed size\n",
        "> * **input_dim**: The size of the vocabulary (num of unique words in the dataset+1).\n",
        " > >   * 1 for padding\n",
        "> * **output_dim**: The dimension of the dense embedding vectors. Each word is represented as a 128-dimensional vector.\n",
        "> * **input_length**: The length of input sequences. Each sequence has been padded to max_len"
      ],
      "metadata": {
        "id": "rPJXF9RFkpXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **SimpleRNN Layer:**: This layer processes the sequences output by the Embedding layer\n",
        "> * **128**: The number of units (neurons) in the RNN. Each unit maintains a hidden state and processes one word at a time in the sequence, updating the hidden state with each word.\n",
        "> * **return_sequences=False**: The RNN will only output the final hidden state after processing the entire sequence. If True, it would return the hidden state at each timestep, which is useful for stacking RNN layers."
      ],
      "metadata": {
        "id": "QEzpDxAekpXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Dense Layer**:This layer is used to classify the final output from the RNN into one of the three cancer types\n",
        "> * **3**: The number of output units, corresponding to the number of classes (e.g., Thyroid Cancer, Colon Cancer, Lung Cancer).\n",
        "> * **activation='softmax'**: The softmax activation function converts the output of the Dense layer into probabilities, summing to 1 across the 3 classes."
      ],
      "metadata": {
        "id": "RiWPMYuPkpXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📎Compile the Model"
      ],
      "metadata": {
        "id": "-x9f7ZgQkpXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "coVVYIgRkpXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **optimizer='adam'**: The Adam optimizer adjusts the learning rate dynamically during training, leading to faster convergence and better performance.\n",
        "> * **loss='categorical_crossentropy'**: The categorical crossentropy loss function is ideal for multi-class classification problems, comparing predicted probabilities with the true class labels.\n",
        "> * **metrics=['accuracy']**: Accuracy is tracked during training to provide a clear and intuitive measure of how well the model is performing in classifying the data."
      ],
      "metadata": {
        "id": "6SmnfucTkpXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📎Train the Model"
      ],
      "metadata": {
        "id": "eiHdvC2skpXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_pad, y_train_cat, epochs=5, batch_size=32, validation_split=0.2)\n",
        "history"
      ],
      "metadata": {
        "trusted": true,
        "id": "wuvdraqVkpXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> * **X_train_pad** and **y_train_cat**: These are the input data and corresponding labels used for training the model.\n",
        "> * **epochs=5**: The model will be trained over 5 full iterations through the dataset.\n",
        "> * **batch_size=32**: The data will be processed in batches of 32 samples at a time, leading to frequent updates to the model's weights.\n",
        "> * **validation_split=0.2**: 20% of the training data will be used for validation, allowing you to monitor the model's performance on unseen data during training.\n",
        "> * **history**: This object stores the training history, which can be analyzed to evaluate the model's performance over time"
      ],
      "metadata": {
        "id": "nj7G1hlKkpXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📎Evaluate the Model"
      ],
      "metadata": {
        "id": "o9WZCq0WkpXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_pad, y_test_cat)\n",
        "\n",
        "print(f'Test loss: {loss}')\n",
        "print(f'Test accuracy: {accuracy}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "VdUd2TSakpXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "predictions = model.predict(X_test_pad)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "predicted_labels"
      ],
      "metadata": {
        "trusted": true,
        "id": "VCSHut7AkpXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_df = pd.DataFrame({\n",
        "    'Actual Labels': y_test_,\n",
        "    'Predicted Labels': predicted_labels\n",
        "})\n",
        "\n",
        "res_df[:30]\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "XGw43q2MkpXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(classification_report(y_test_, predicted_labels, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "LvMgNpTNkpXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test_, predicted_labels)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "0MXrv8wtkpXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Wish u luck** 💕\n",
        "* **Esraa Meslam**"
      ],
      "metadata": {
        "id": "RwnVKF9MkpXa"
      }
    }
  ]
}