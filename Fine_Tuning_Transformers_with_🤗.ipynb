{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Mws_g7ZWrTgZ",
        "CMc9R-kSrTgo",
        "x5lfdZtmus2M",
        "CBfv1M9IZXJu",
        "H4A6YOWXbMQD",
        "Wrp26fLxjsJ9"
      ],
      "gpuType": "T4",
      "provenance": [],
      "name": "Fine Tuning Transformers with ðŸ¤—",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 4033428,
          "sourceType": "datasetVersion",
          "datasetId": 2389764
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thesis-AfaanOromooChatGPT2025/MedPromptX/blob/main/Fine_Tuning_Transformers_with_%F0%9F%A4%97.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "falgunipatel19_biomedical_text_publication_classification_path = kagglehub.dataset_download('falgunipatel19/biomedical-text-publication-classification')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "OXAmYOrUfMTA"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**"
      ],
      "metadata": {
        "id": "Mws_g7ZWrTgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to this notebook, where we will delve into the fascinating world of **fine-tuning Transformer** architectures for specific **downstream tasks**.\n",
        "\n",
        "In our previous notebooks, we delved into the **theory behind Transformers** and explored how to use **Transformers**. Now, it's time to take our understanding a **step further** and explore how we can **adapt and fine-tune Transformer** models to suit our specific needs.\n",
        "\n",
        "- **Transformers** are typically pretrained on **large corpora of text**, imbuing them with **rich contextual information** about language. While **pretrained Transformers** can be **incredibly powerful** out of the box, what if we want to **tailor them to our own dataset** or **fine-tune** them for a **specific downstream task?**\n",
        "\n",
        "That's precisely what we'll be **uncovering in this notebook** â€“ the **art and science of fine-tuning Transformers**. We'll explore **techniques** to **adapt pretrained Transformers** to our unique datasets and optimize them for specific tasks, whether it's text classification, named entity recognition, sentiment analysis, or any other NLP task you can imagine.\n",
        "\n",
        "So buckle up and get ready to embark on an **exciting journey** of **fine-tuning Transformer** architectures for **unparalleled performance** and efficiency in your **NLP projects**. Let's dive in!\n"
      ],
      "metadata": {
        "id": "twM37_I6rTgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Environmental Setup**"
      ],
      "metadata": {
        "id": "vZDDt1WprTgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, our primary objective is to meticulously gather all essential libraries necessary for the seamless operation of our system. We will ensure to procure pertinent datasets and download any vital resources imperative for our functionality. Additionally, we'll establish key constants pivotal for subsequent operations."
      ],
      "metadata": {
        "id": "tkafPnIJrTgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download libraries\n",
        "!pip install datasets transformers -q\n",
        "!pip install transformers[torch] -q\n",
        "!pip install accelerate>=0.21.0 -U -q"
      ],
      "metadata": {
        "id": "t9rpyQD8rTgk",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:02:22.165304Z",
          "iopub.execute_input": "2024-07-16T15:02:22.165658Z",
          "iopub.status.idle": "2024-07-16T15:03:02.530878Z",
          "shell.execute_reply.started": "2024-07-16T15:02:22.165614Z",
          "shell.execute_reply": "2024-07-16T15:03:02.529683Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base Library\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Data\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "# Model Training\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "\n",
        "# Model Trainer\n",
        "from transformers import Trainer\n",
        "from transformers import AutoConfig\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "# Model Evaluation\n",
        "!pip install evaluate -q -U\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "nq1oTjPRrTgn",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:03:02.532811Z",
          "iopub.execute_input": "2024-07-16T15:03:02.533124Z",
          "iopub.status.idle": "2024-07-16T15:03:46.064577Z",
          "shell.execute_reply.started": "2024-07-16T15:03:02.533097Z",
          "shell.execute_reply": "2024-07-16T15:03:46.06372Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "BATCH_SIZE = 8\n",
        "CHECKPOINT = \"bert-base-uncased\"\n",
        "FILE_PATH = \"/kaggle/input/biomedical-text-publication-classification/alldata_1_for_kaggle.csv\""
      ],
      "metadata": {
        "id": "afG-XtzYrTgo",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:03:47.955719Z",
          "iopub.execute_input": "2024-07-16T15:03:47.956812Z",
          "iopub.status.idle": "2024-07-16T15:03:47.960988Z",
          "shell.execute_reply.started": "2024-07-16T15:03:47.956781Z",
          "shell.execute_reply": "2024-07-16T15:03:47.960062Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Loading**"
      ],
      "metadata": {
        "id": "CMc9R-kSrTgo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To facilitate efficient loading of data into memory, we can leverage the capabilities of the Hugging Face dataset library. This powerful tool streamlines the process, enabling seamless integration of the required diabetes datasets into our system's memory."
      ],
      "metadata": {
        "id": "EATho62frTgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load & transform data\n",
        "data = pd.read_csv(FILE_PATH, encoding=\"latin1\")\n",
        "data.columns = [\"ID\", \"Label\", \"Text\"]\n",
        "data.drop(columns=['ID'], inplace=True)\n",
        "data.head()\n",
        "\n",
        "# Save as CSV\n",
        "data.to_csv(\"medical_text.csv\", index=False)"
      ],
      "metadata": {
        "id": "8o8u9yZasmEK",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:03:51.412688Z",
          "iopub.execute_input": "2024-07-16T15:03:51.413511Z",
          "iopub.status.idle": "2024-07-16T15:04:02.654413Z",
          "shell.execute_reply.started": "2024-07-16T15:03:51.413479Z",
          "shell.execute_reply": "2024-07-16T15:04:02.653612Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = sorted(data.Label.unique())\n",
        "class_mapping = {name:index for index, name in enumerate(class_names)}"
      ],
      "metadata": {
        "id": "EikQylk8bwX8",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:04:02.656284Z",
          "iopub.execute_input": "2024-07-16T15:04:02.656738Z",
          "iopub.status.idle": "2024-07-16T15:04:02.666683Z",
          "shell.execute_reply.started": "2024-07-16T15:04:02.656705Z",
          "shell.execute_reply": "2024-07-16T15:04:02.665703Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset with the correct encoding\n",
        "data_dict = load_dataset(\"csv\", data_files=\"/kaggle/working/medical_text.csv\", encoding=\"latin1\")\n",
        "\n",
        "# Generate a Train Test Split\n",
        "data_dict = data_dict[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# Select Training and Testing data\n",
        "train_ds = data_dict[\"train\"]\n",
        "test_ds = data_dict[\"test\"]"
      ],
      "metadata": {
        "id": "mKdwHT6ZrTgp",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:04:02.66778Z",
          "iopub.execute_input": "2024-07-16T15:04:02.668052Z",
          "iopub.status.idle": "2024-07-16T15:04:05.108687Z",
          "shell.execute_reply.started": "2024-07-16T15:04:02.668029Z",
          "shell.execute_reply": "2024-07-16T15:04:05.107803Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenizer**"
      ],
      "metadata": {
        "id": "x5lfdZtmus2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Natural Language Processing (NLP) involves text tokenization as a key step in converting human language into a form that can be analyzed and understood by computers.\n",
        "\n",
        "Tokenization involves breaking down text into smaller units, or tokens, and converting these tokens into numeric format, allowing for efficient computation and analysis. The process of tokenization is done in two stages:\n",
        "\n",
        "- first, the text is split into individual words (word-level tokenization),\n",
        "\n",
        "- and then those words are converted into numeric format (conversion to numeric format). This is done by assigning a unique numeric ID to each word in the vocabulary, which is based on the size of the vocabulary.\n",
        "\n",
        "Overall, tokenization is essential for NLP as it transforms unstructured text data into a structured and standardized format, enabling the analysis of human language."
      ],
      "metadata": {
        "id": "OtZ6vm7PYFHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT)\n",
        "\n",
        "# Preprocessing function\n",
        "def apply_tokenizer(sample):\n",
        "    return tokenizer(sample['Text'], truncation=True, padding=True)\n",
        "\n",
        "def text_to_num_label(sample):\n",
        "    return {'labels': [class_mapping[label] for label in sample['Label']]}"
      ],
      "metadata": {
        "id": "6odsQsmiusqG",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:04:14.501765Z",
          "iopub.execute_input": "2024-07-16T15:04:14.502383Z",
          "iopub.status.idle": "2024-07-16T15:04:15.488137Z",
          "shell.execute_reply.started": "2024-07-16T15:04:14.502351Z",
          "shell.execute_reply": "2024-07-16T15:04:15.48728Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batching sequences for preprocessing enhances efficiency compared to processing individual samples sequentially. This approach significantly reduces total processing time, making it more efficient and streamlined."
      ],
      "metadata": {
        "id": "JVlZshcYYoQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-16T15:04:15.494932Z",
          "iopub.execute_input": "2024-07-16T15:04:15.495203Z",
          "iopub.status.idle": "2024-07-16T15:04:15.501524Z",
          "shell.execute_reply.started": "2024-07-16T15:04:15.495181Z",
          "shell.execute_reply": "2024-07-16T15:04:15.500562Z"
        },
        "trusted": true,
        "id": "LuWmfhOBfMTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This will take some time\n",
        "train_ds = train_ds.map(apply_tokenizer, batched=True)\n",
        "test_ds = test_ds.map(apply_tokenizer, batched=True)"
      ],
      "metadata": {
        "id": "OaqIsQjtum3M",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:04:16.046884Z",
          "iopub.execute_input": "2024-07-16T15:04:16.047219Z",
          "iopub.status.idle": "2024-07-16T15:05:15.807515Z",
          "shell.execute_reply.started": "2024-07-16T15:04:16.047195Z",
          "shell.execute_reply": "2024-07-16T15:05:15.806513Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(text_to_num_label, batched=True)\n",
        "test_ds = test_ds.map(text_to_num_label, batched=True)"
      ],
      "metadata": {
        "id": "edyNO5IMcLI0",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:05:15.809222Z",
          "iopub.execute_input": "2024-07-16T15:05:15.809526Z",
          "iopub.status.idle": "2024-07-16T15:05:16.376697Z",
          "shell.execute_reply.started": "2024-07-16T15:05:15.809501Z",
          "shell.execute_reply": "2024-07-16T15:05:16.375841Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we've implemented two types of data processing steps. Firstly, we tokenized the textual data using a tokenizer. Secondly, we converted the textual labels into numeric format."
      ],
      "metadata": {
        "id": "LWwFc_0xc_Lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Keras - Training**"
      ],
      "metadata": {
        "id": "H4A6YOWXbMQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To proceed with the training phase, we'll begin by loading our transformer model. Next, we'll combine this loaded model with the necessary components, such as optimizer and loss function, before advancing to the training process."
      ],
      "metadata": {
        "id": "kA-kTFXadbye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loading Transformer\n",
        "# model = TFAutoModelForSequenceClassification.from_pretrained(CHECKPOINT, num_labels=len(class_names))\n",
        "# model.layers"
      ],
      "metadata": {
        "id": "NJbTUc8MbMIX",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:06:05.273233Z",
          "iopub.execute_input": "2024-07-16T15:06:05.274102Z",
          "iopub.status.idle": "2024-07-16T15:06:05.278611Z",
          "shell.execute_reply.started": "2024-07-16T15:06:05.274066Z",
          "shell.execute_reply": "2024-07-16T15:06:05.277585Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the widespread popularity and efficient performance of the BERT Transformer architecture, we've decided to leverage this model for our task.\n",
        "\n",
        "> BERT (Bidirectional Encoder Representations from Transformers) has demonstrated remarkable effectiveness across various natural language processing tasks, making it a robust choice for our application. We'll integrate BERT into our training pipeline to capitalize on its advanced capabilities and achieve optimal performance in our task."
      ],
      "metadata": {
        "id": "bz-Xo5tzdtyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Polynomial Decay Learning Rate\n",
        "# num_epochs = 50\n",
        "# num_train_steps = len(tf_train) * BATCH_SIZE * num_epochs\n",
        "\n",
        "# # Initilize Polynomial Decay\n",
        "# polynomial_decay_schedule = PolynomialDecay(\n",
        "#     initial_learning_rate=2e-6,\n",
        "#     end_learning_rate=0.0,\n",
        "#     decay_steps=num_train_steps\n",
        "# )\n",
        "\n",
        "# # Define Polynomial Decay Callback\n",
        "# polynomial_decay_callback = keras.callbacks.LearningRateScheduler(polynomial_decay_schedule)"
      ],
      "metadata": {
        "id": "QBtpONELfxlp",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:06:05.797351Z",
          "iopub.execute_input": "2024-07-16T15:06:05.797727Z",
          "iopub.status.idle": "2024-07-16T15:06:05.802124Z",
          "shell.execute_reply.started": "2024-07-16T15:06:05.797696Z",
          "shell.execute_reply": "2024-07-16T15:06:05.801216Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Model Compilation\n",
        "# model.compile(\n",
        "#     loss=losses.SparseCategoricalCrossentropy(),\n",
        "#     optimizer=\"adam\",\n",
        "#     metrics=['accuracy']\n",
        "# )"
      ],
      "metadata": {
        "id": "1PgdpHTYdr9a",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:06:06.024055Z",
          "iopub.execute_input": "2024-07-16T15:06:06.024438Z",
          "iopub.status.idle": "2024-07-16T15:06:06.029059Z",
          "shell.execute_reply.started": "2024-07-16T15:06:06.024406Z",
          "shell.execute_reply": "2024-07-16T15:06:06.028006Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Model Training\n",
        "# history = model.fit(\n",
        "#     tf_train,\n",
        "#     validation_data=tf_test,\n",
        "#     epochs=num_epochs,\n",
        "#     callbacks=[\n",
        "#         keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
        "#         keras.callbacks.ModelCheckpoint(\"FineTuned-BERT.keras\", save_best_only=True),\n",
        "#         polynomial_decay_callback\n",
        "#     ]\n",
        "# )"
      ],
      "metadata": {
        "id": "ylvNo6Guep98",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:06:06.340553Z",
          "iopub.execute_input": "2024-07-16T15:06:06.341343Z",
          "iopub.status.idle": "2024-07-16T15:06:06.345199Z",
          "shell.execute_reply.started": "2024-07-16T15:06:06.341313Z",
          "shell.execute_reply": "2024-07-16T15:06:06.344311Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HuggingFace - Trainer**"
      ],
      "metadata": {
        "id": "Wrp26fLxjsJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training deep learning models traditionally involves using the `fit` method in Keras, often backed by TensorFlow. However, there is a more efficient approach for models associated with Hugging Face. Instead of relying solely on Keras, which may not always provide the optimal training parameters, one can use the Hugging Face Trainer. The Hugging Face Trainer offers a streamlined and effective way to train models, ensuring the process is faster and better optimized with the correct training arguments."
      ],
      "metadata": {
        "id": "A0Rp1E0Fjw1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(CHECKPOINT, num_labels=len(class_names))"
      ],
      "metadata": {
        "id": "i3Onp35JjvQI",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:06:08.933249Z",
          "iopub.execute_input": "2024-07-16T15:06:08.934048Z",
          "iopub.status.idle": "2024-07-16T15:06:11.915353Z",
          "shell.execute_reply.started": "2024-07-16T15:06:08.934015Z",
          "shell.execute_reply": "2024-07-16T15:06:11.914513Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Default id 2 label\n",
        "default_id2label = model.config.id2label\n",
        "print(f\"Default ID 2 Label Mapping : {default_id2label}\")\n",
        "\n",
        "# Mapping with respect to Dataset\n",
        "id2label = dict(enumerate(class_names))\n",
        "print(f\"Dataset ID 2 Label Mapping : {id2label}\")"
      ],
      "metadata": {
        "id": "0Y9_As4BkqYJ",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:06:11.917271Z",
          "iopub.execute_input": "2024-07-16T15:06:11.918129Z",
          "iopub.status.idle": "2024-07-16T15:06:11.9232Z",
          "shell.execute_reply.started": "2024-07-16T15:06:11.918092Z",
          "shell.execute_reply": "2024-07-16T15:06:11.922144Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To update or change the model configurations, we need to follow these steps."
      ],
      "metadata": {
        "id": "4ZJ_Uy90lK7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Label to ID Mapping\n",
        "label2id = {v:k for k, v in id2label.items()}\n",
        "\n",
        "# Update Model COnfigurations\n",
        "config = AutoConfig.from_pretrained(CHECKPOINT, num_labels=len(class_names))\n",
        "config.id2label = id2label\n",
        "config.label2id = label2id\n",
        "\n",
        "# Add configs to the Model\n",
        "model.config = config"
      ],
      "metadata": {
        "id": "g4h3rXx3lWe2",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:06:13.015142Z",
          "iopub.execute_input": "2024-07-16T15:06:13.016007Z",
          "iopub.status.idle": "2024-07-16T15:06:13.094022Z",
          "shell.execute_reply.started": "2024-07-16T15:06:13.015972Z",
          "shell.execute_reply": "2024-07-16T15:06:13.093316Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While it is possible to directly change the model configurations, following these steps is recommended for greater security and stability."
      ],
      "metadata": {
        "id": "DmC_q8hdlmzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All Model Configurations\n",
        "model.config"
      ],
      "metadata": {
        "id": "HxvfPINilaH7",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:06:14.95316Z",
          "iopub.execute_input": "2024-07-16T15:06:14.953962Z",
          "iopub.status.idle": "2024-07-16T15:06:14.960799Z",
          "shell.execute_reply.started": "2024-07-16T15:06:14.95393Z",
          "shell.execute_reply": "2024-07-16T15:06:14.959819Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To train a model using the Hugging Face Trainer, we first need to define the training arguments. These arguments are crucial as they dictate the training process's specifics, including parameters such as learning rate, logging directory, gradient accumulation steps, batch size, and various other settings. The training arguments ensure that the model is trained efficiently and effectively by providing the necessary configurations to optimize the learning process. Properly setting these parameters can significantly impact the model's performance and the stability of the training procedure."
      ],
      "metadata": {
        "id": "E8CF5mQ7mbPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Constants\n",
        "BATCH_SIZE = 2                                 # Change this in case of CUDA OOM Error\n",
        "LR = 5e-5\n",
        "EPOCHS = 10\n",
        "\n",
        "# Set training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"FineTuned-BERT\",                # Output Directory to save Logs\n",
        "    learning_rate=LR,                           # Learning Rate\n",
        "    num_train_epochs=EPOCHS,                    # Total Number of Epochs\n",
        "    per_device_train_batch_size=BATCH_SIZE,     # Batch Size for Training\n",
        "    per_device_eval_batch_size=BATCH_SIZE,      # Batch Size for evaluation\n",
        "    logging_steps=10,                           # Get logs after n epochs\n",
        "    evaluation_strategy=\"epoch\",                # Perform evaluation after every epoch\n",
        "    save_strategy=\"epoch\",                      # Save model after Epoch\n",
        "    load_best_model_at_end=True,                # Load the best model at the end of the training (like EarlyStopping)\n",
        "    fp16=True,                                  # Enable mixed precision training\n",
        "    gradient_accumulation_steps=2,              # Steps after which Gradients are Accumulated\n",
        "    weight_decay=0.01,                          # Weight Decay parameter\n",
        "    warmup_steps=100,                           # Number of Warmup Steps\n",
        "    report_to=\"none\"                            # We can report to Tensorboard, wandb, etc\n",
        ")"
      ],
      "metadata": {
        "id": "mXudNdm9mxoh",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:06:16.147382Z",
          "iopub.execute_input": "2024-07-16T15:06:16.148217Z",
          "iopub.status.idle": "2024-07-16T15:06:16.267753Z",
          "shell.execute_reply.started": "2024-07-16T15:06:16.148184Z",
          "shell.execute_reply": "2024-07-16T15:06:16.266792Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One great feature of the Hugging Face Trainer is the ability to add custom metrics for model evaluation. This flexibility allows you to compute and monitor any metric you need, providing deeper insights into your model's performance."
      ],
      "metadata": {
        "id": "bFynI_OSfMTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Metrics\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "precision_metric = evaluate.load(\"precision\")\n",
        "recall_metric = evaluate.load(\"recall\")\n",
        "f1_score_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# Define Custom Metric\n",
        "def compute_metrics(preds):\n",
        "\n",
        "    # Get Logits and Labels from the preds\n",
        "    logits, labels = preds\n",
        "\n",
        "    # Obtain prediction from the preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    # Evaluate Model Performance\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)['accuracy']\n",
        "    precision = precision_metric.compute(predictions=predictions, references=labels, average=\"micro\")['precision']\n",
        "    recall = recall_metric.compute(predictions=predictions, references=labels, average=\"micro\")['recall']\n",
        "    f1_score = f1_score_metric.compute(predictions=predictions, references=labels, average=\"micro\")['f1']\n",
        "\n",
        "    return {\n",
        "        \"accuracy\" : accuracy,\n",
        "        \"precision\" : precision,\n",
        "        \"recall\" : recall,\n",
        "        \"f1_score\" : f1_score\n",
        "    }\n",
        "\n",
        "\n",
        "# Model Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "UpCtnq35oKiG",
        "execution": {
          "iopub.status.busy": "2024-07-16T15:06:23.475541Z",
          "iopub.execute_input": "2024-07-16T15:06:23.475969Z",
          "iopub.status.idle": "2024-07-16T15:06:25.666654Z",
          "shell.execute_reply.started": "2024-07-16T15:06:23.47594Z",
          "shell.execute_reply": "2024-07-16T15:06:25.665821Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "cktnc9aCfMTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-16T13:15:41.215588Z",
          "iopub.execute_input": "2024-07-16T13:15:41.215873Z",
          "iopub.status.idle": "2024-07-16T14:40:21.836441Z",
          "shell.execute_reply.started": "2024-07-16T13:15:41.215848Z",
          "shell.execute_reply": "2024-07-16T14:40:21.83542Z"
        },
        "trusted": true,
        "id": "fiadTMwqfMTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training process and the corresponding evaluation metrics are summarized in the table. Here's a detailed and specific analysis focusing on the main sections:\n",
        "\n",
        "**Training Loss:**\n",
        "- The training loss demonstrates an initial decrease, indicating effective learning during the initial epochs. The training loss drops to zero in several epochs (3, 4, 5, and 10), which suggests potential overfitting as the model perfectly fits the training data. However, some fluctuations in later epochs (6, 7, 8, and 9) suggest attempts to regularize and mitigate overfitting.\n",
        "\n",
        "**Validation Loss:**\n",
        "- The validation loss shows a general decreasing trend over the epochs, indicating improving model generalization. Notably, the validation loss stabilizes around a lower value in later epochs, reflecting the model's capacity to generalize from the training data to unseen validation data.\n",
        "\n",
        "**Evaluation Metrics (Accuracy, Precision, Recall, F1 Score):**\n",
        "- The accuracy, precision, recall, and F1 score metrics are consistently high across all epochs, ranging from 0.9214 to 0.9914. This consistent performance across all evaluation metrics demonstrates the model's robustness and reliability in classification tasks.\n",
        "- The highest accuracy and corresponding metrics are observed in epoch 7, with values of 0.9914 across all evaluation metrics. This indicates peak model performance, combining both high accuracy and low validation loss.\n",
        "\n",
        "**General Observations:**\n",
        "- **Early Training**: The initial epochs (1 and 2) show significant improvements in both training and validation metrics, suggesting effective initial learning and model optimization.\n",
        "- **Overfitting Signs**: The zero training loss in several epochs indicates potential overfitting. Despite this, the model maintains high evaluation metrics, indicating it still generalizes well to validation data.\n",
        "- **Stabilization**: In later epochs, the validation loss and evaluation metrics stabilize, reflecting a well-regularized model with consistent performance.\n",
        "\n",
        "**Conclusion:**\n",
        "Overall, the model demonstrates strong learning capability with initial rapid improvements, signs of overfitting managed through regularization, and consistently high evaluation metrics. This indicates a well-performing model with reliable generalization to unseen data, suitable for the intended classification task."
      ],
      "metadata": {
        "id": "WKDut8hVfMTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "4rfu_hjZfMTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "eval_res = trainer.evaluate()\n",
        "\n",
        "print(f\"Evaluation Loss     : {eval_res['eval_loss']}\")\n",
        "print(f\"Evaluation Accuracy : {eval_res['eval_accuracy']}\")\n",
        "print(f\"Evaluation Precision: {eval_res['eval_precision']}\")\n",
        "print(f\"Evaluation Recall   : {eval_res['eval_recall']}\")\n",
        "print(f\"Evaluation F1 Score : {eval_res['eval_f1_score']}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-16T14:44:23.659717Z",
          "iopub.execute_input": "2024-07-16T14:44:23.660082Z",
          "iopub.status.idle": "2024-07-16T14:45:01.449726Z",
          "shell.execute_reply.started": "2024-07-16T14:44:23.660054Z",
          "shell.execute_reply": "2024-07-16T14:45:01.448788Z"
        },
        "trusted": true,
        "id": "9Ol4hRVSfMTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics Analysis:**\n",
        "\n",
        "The evaluation metrics provide a comprehensive overview of the model's performance on the validation dataset:\n",
        "\n",
        "- **Evaluation Loss**: 0.1085 This low loss value indicates a small discrepancy between the predicted and actual values, suggesting the model's predictions are highly accurate.\n",
        "\n",
        "- **Evaluation Accuracy**: 0.9914 This metric indicates that approximately 99.14% of the predictions made by the model are correct, showcasing its high overall accuracy.\n",
        "\n",
        "- **Evaluation Precision**: 0.9914 Precision measures the proportion of true positive predictions out of all positive predictions. A precision of 99.14% demonstrates that the model is highly effective at correctly identifying positive instances with very few false positives.\n",
        "\n",
        "- **Evaluation Recall**: 0.9914 Recall measures the proportion of true positive predictions out of all actual positives. With a recall of 99.14%, the model successfully identifies the vast majority of positive instances, minimizing false negatives.\n",
        "\n",
        "- **Evaluation F1 Score**: 0.9914 The F1 score is the harmonic mean of precision and recall, providing a balanced measure of the modelâ€™s performance. A score of 99.14% indicates that the model maintains a strong balance between precision and recall.\n",
        "\n",
        "**General Observations:**\n",
        "- The consistency across accuracy, precision, recall, and F1 score, all being 99.14%, suggests that the model performs uniformly well across different evaluation metrics.\n",
        "- The low evaluation loss combined with high accuracy and other metrics indicates that the model generalizes well to unseen data without overfitting.\n",
        "- Such high values in all these metrics demonstrate that the model is both precise and comprehensive in its classification tasks, making very few errors in both false positives and false negatives.\n",
        "\n",
        "**Conclusion:**\n",
        "The evaluation results indicate a highly effective model with excellent generalization capabilities. The model achieves near-perfect accuracy, precision, recall, and F1 scores, highlighting its robustness and reliability in making accurate predictions. These metrics collectively suggest that the model is well-suited for practical applications where high precision and recall are crucial."
      ],
      "metadata": {
        "id": "cJ9WruznfMTR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving Model**"
      ],
      "metadata": {
        "id": "xpmx91pdfMTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"fintuned-bert\")\n",
        "tokenizer.save_pretrained(\"fintuned-bert\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-16T14:43:02.928837Z",
          "iopub.execute_input": "2024-07-16T14:43:02.929478Z",
          "iopub.status.idle": "2024-07-16T14:43:03.773505Z",
          "shell.execute_reply.started": "2024-07-16T14:43:02.929444Z",
          "shell.execute_reply": "2024-07-16T14:43:03.772565Z"
        },
        "trusted": true,
        "id": "LPtPxr5rfMTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: Training and evaluation results may differ a bit due to re run of the notebook/kernel.\n",
        "\n",
        "---\n",
        "**DeepNets**"
      ],
      "metadata": {
        "id": "Q2yguoBVfMTS"
      }
    }
  ]
}